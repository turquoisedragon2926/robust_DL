{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1699074477977,"user":{"displayName":"Turquoise Dragon","userId":"08320414478638444844"},"user_tz":240},"id":"oMU-5NWxiY-7","outputId":"8c58c47b-eaf8-4507-983b-d5c6d0044ae2"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/MyDrive/robust_DL\n","%mkdir results"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from __future__ import print_function\n","import os\n","import argparse\n","import matplotlib.pyplot as plt\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import torch.nn.functional as F\n","from losses.trades import trades_loss\n","import copy\n","import torch\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","from models.wideresnet import *\n","from models.resnet import *\n","from models.small_cnn import *\n","from torch.utils.data import Dataset, DataLoader\n","from models.AlexNet import AlexNet\n","from torch.utils.data.sampler import SubsetRandomSampler\n","import json"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["class Data:\n","  def __init__(self, train_loader, valid_loader, test_loader, attack_loader):\n","    self.train_loader = train_loader\n","    self.valid_loader = valid_loader\n","    self.test_loader = test_loader\n","    self.attack_loader = attack_loader\n","\n","class Model:\n","  model = None\n","  def __init__(self, id):\n","    self.id = id\n","\n","class Loss:\n","  def __init__(self, loss_fn, id=None):\n","    self.loss_fn = loss_fn\n","    self.id = id\n","\n","class Configuration:\n","  def __init__(self, data, model, loss, attack, model_pt=None, id=None):\n","    self.data = data\n","    self.model = model\n","    self.loss = loss\n","    self.attack = attack\n","    self.model_pt = model_pt # Should move this to model\n","\n","    self.id = id\n","\n","  def getConfig(self):\n","    return self.data, self.model, self.loss, self.attack\n","\n","  def getId(self):\n","    return self.id\n","\n","class CIFAR10CDataset(Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image = self.data[idx]\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","def general_trades_loss_fn(beta=6.0, epsilon=0.3, step_size=0.007, num_steps=10):\n","  def trades_loss_fn(model, data, target, optimizer):\n","    return trades_loss(model=model, x_natural=data, y=target, optimizer=optimizer, step_size=step_size,\n","                      epsilon=epsilon, perturb_steps=num_steps, beta=beta, distance='l_inf')\n","  return trades_loss_fn\n","\n","def ce_loss_fn(model, data, target, optimizer):\n","    return F.cross_entropy(model(data), target)\n","    \n","def identity_attack(model, X, y):\n","  out = model(X)\n","  acc = (out.data.max(1)[1] == y.data).float().sum()\n","  return acc.item()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def accuracy(model, data_loader, device):\n","    print('EVAL')\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(data_loader):\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs, 1)\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","\n","    return 100. * correct / total\n","\n","def robust_accuracy(model, attack, data_loader, device):\n","    print('ROBUST EVAL')\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    for data, target in data_loader:\n","        data, target = data.to(device), target.to(device)\n","\n","        X, y = Variable(data, requires_grad=True), Variable(target)\n","        correct_count = attack(model, X, y)\n","        correct += correct_count\n","        total += target.size(0)\n","    return 100. * correct / total \n","\n","def train(model, data, loss, config, epochs, eval_interval, device):\n","  print('TRAINING')\n","  data_loader = data.train_loader\n","  valid_loader = data.valid_loader\n","  attack_loader = data.attack_loader\n","\n","  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","  # TODO: We can move the optimizer to a field of Loss object\n","\n","  model.to(device)\n","  if config.model_pt is not None:\n","    model.load_state_dict(torch.load(config.model_pt))\n","\n","  best_eval_acc = 0.0\n","  patience = 5  # number of VAL Acc values observed after best value to stop training\n","\n","  # Initialize lists to store per-epoch loss and validation accuracy\n","  epoch_losses = []\n","  eval_accuracies = []\n","\n","  for epoch in range(1, epochs+1):\n","    model.train()\n","    total_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        l = loss.loss_fn(model, data, target, optimizer)\n","        l.backward()\n","        optimizer.step()\n","        total_loss += l.item()\n","\n","        print(loss.id + f\" @ EP={epoch} & Batch idx \" + str(batch_idx) + \" / \" + str(len(data_loader) - 1) + \" Loss: \" + str(l.item()))\n","    \n","    epoch_losses.append(total_loss / len(data_loader))\n","\n","    if epoch == 1 or epoch % eval_interval == 0 or epoch == epochs:\n","      eval_acc= accuracy(model, valid_loader, device)\n","      eval_accuracies.append(eval_acc) \n","\n","      if (eval_acc > best_eval_acc):  # best so far so save checkpoint to restore later\n","        best_eval_acc = eval_acc\n","        patience_count = 0\n","        torch.save(model.state_dict(), os.path.join(\"weights\", loss.id + \".pt\"))\n","        torch.save(optimizer.state_dict(), os.path.join(\"optimizers\", loss.id +  \".tar\"))\n","      else:\n","          patience_count += 1\n","\n","    # Plotting the loss and accuracy\n","    plt.figure(figsize=(12, 5))\n","    plt.suptitle(loss.id)\n","\n","    # Plot training loss\n","    plt.subplot(1, 2, 1)\n","    plt.plot(epoch_losses, label='Training Loss')\n","    plt.title('Loss vs. Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","\n","    # Plot validation accuracy\n","    plt.subplot(1, 2, 2)\n","    plt.plot(eval_accuracies, label='Validation Accuracy')\n","\n","    if epoch == epochs or patience_count >= patience:\n","      # Get the CIFAR 10 C evaluation accuracy and plot the horizontal line\n","      cifar10c_eval_acc = robust_accuracy(model, config.attack, attack_loader, device)\n","      plt.axhline(y=cifar10c_eval_acc, color='r', linestyle='-', label='CIFAR 10 C EVAL')\n","\n","    plt.title('Validation Accuracy vs. Epochs')\n","    plt.xlabel('Epochs')\n","    plt.ylabel('Accuracy')\n","    plt.legend()\n","\n","    # Save the plots\n","    if not os.path.exists('plots'):\n","        os.makedirs('plots')\n","    plt.savefig(os.path.join('plots', loss.id + '_training_validation_plot.png'))\n","    plt.close()\n","\n","    if patience_count >= patience:\n","      print(f\"Early Stopping!, epoch {epoch}\")\n","      break\n","\n","  return total_loss\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def run_experiment(num_epoch=2, valid_size=0.2, eval_interval=1):\n","  transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),])\n","  transform_test = transforms.Compose([\n","    transforms.ToTensor(),])\n","  use_cuda = torch.cuda.is_available()\n","  kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","  transform_attack = transforms.Compose([transforms.ToTensor(),])\n","\n","  trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n","  validset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n","  testset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n","  num_train = len(trainset)\n","  indices = list(range(num_train))\n","  split = int(np.floor(valid_size * num_train))\n","  train_idx, valid_idx = indices[split:], indices[:split]\n","  train_sampler = SubsetRandomSampler(train_idx)\n","  valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","\n","  cifar10_train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, sampler=train_sampler, **kwargs)\n","  cifar10_valid_loader = torch.utils.data.DataLoader(trainset , batch_size=128, sampler=valid_sampler, **kwargs)\n","  cifar10_test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, **kwargs)\n","\n","\n","  transform_cifar10c = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))])\n","  images = np.load('../data/CIFAR-10-C/spatter.npy') # Set this to whatever we want\n","  labels = np.load('../data/CIFAR-10-C/labels.npy')\n","  cifar10c_dataset = CIFAR10CDataset(data=images,labels=labels,transform=transform_cifar10c)\n","  cifar10c_attack_loader = DataLoader(cifar10c_dataset, batch_size=200, shuffle=False)\n","\n","  cifar10_c_data = Data(cifar10_train_loader, cifar10_valid_loader,cifar10_test_loader, cifar10c_attack_loader)\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","  configurations = []\n","  final_loss = {}\n","  natural_accuracy = {}\n","  robustness_accuracy = {}\n","\n","  for alpha in [5, 6]:\n","    beta = 1 / alpha\n","    id = f'CIFARC10:Alexnet:TRADES_LOSS:BETA={beta}'\n","    model_pt = None # os.path.join(\"weights\", f'CIFARC10:RESNET18:TRADES_LOSS:BETA={beta}_ep=0.pt')\n","\n","    alexnet = AlexNet().to(device)\n","    trades_loss_beta = Loss(general_trades_loss_fn(beta=beta), id)\n","    config1 = Configuration(cifar10_c_data, alexnet, trades_loss_beta, identity_attack, model_pt, trades_loss_beta.id)\n","    configurations.append(config1)\n","\n","  alexnet = AlexNet().to(device)\n","  id = f'CIFARC10:Alexnet:CE_LOSS'\n","  ce_loss = Loss(ce_loss_fn, id)\n","  baseline = Configuration(cifar10_c_data, alexnet, ce_loss, identity_attack, id=ce_loss.id)\n","  configurations.append(baseline)\n","\n","  for (c, configuration) in enumerate(configurations):\n","    data, model, loss, attack = configuration.getConfig()\n","\n","    with open('results/final_loss.json', 'r') as fp:\n","        final_loss = json.load(fp)\n","    with open('results/natural_accuracy.json', 'r') as fp:\n","        natural_accuracy = json.load(fp)\n","    with open('results/robustness_accuracy.json', 'r') as fp:\n","        robustness_accuracy = json.load(fp)\n","\n","    final_loss[configuration.getId()] = train(model, data, loss, configuration, num_epoch, eval_interval, device)\n","    natural_accuracy[configuration.getId()] = accuracy(model, data.test_loader, device)\n","    robustness_accuracy[configuration.getId()] = robust_accuracy(model, attack, data.attack_loader, device)\n","\n","    with open('results/final_loss.json', 'w') as fp:\n","        json.dump(final_loss, fp)\n","    with open('results/natural_accuracy.json', 'w') as fp:\n","        json.dump(natural_accuracy, fp)\n","    with open('results/robustness_accuracy.json', 'w') as fp:\n","        json.dump(robustness_accuracy, fp)\n","\n","  return final_loss, natural_accuracy, robustness_accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["final_loss, natural_accuracy, robustness_accuracy = run_experiment(num_epoch=50, valid_size=0.2, eval_interval=1)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_result_plot_combined():\n","\n","  # Define the directory where the JSON files are located\n","  directory = 'results/'\n","\n","  # Initialize dictionaries to hold the beta values and corresponding accuracies\n","  natural_accuracies = {}\n","  robustness_accuracies = {}\n","\n","  # Define the configuration pattern we're interested in\n","  config_pattern = 'CIFARC10:Alexnet:TRADES_LOSS:BETA='\n","\n","  # Function to extract beta and accuracies from the json file\n","  def extract_data(file_name):\n","      with open(os.path.join(directory, file_name), 'r') as file:\n","          data = json.load(file)\n","          for config_id, accuracy in data.items():\n","              if config_id.startswith(config_pattern):\n","                  # Extract beta value from the configuration ID\n","                  beta = float(config_id.split('=')[-1])\n","                  if 'final_loss' not in file_name:\n","                      if 'natural_accuracy' in file_name:\n","                          natural_accuracies[beta] = accuracy\n","                      elif 'robustness_accuracy' in file_name:\n","                          robustness_accuracies[beta] = accuracy\n","\n","  # Read data from each JSON file\n","  for file_name in os.listdir(directory):\n","      if file_name.endswith('.json'):\n","          extract_data(file_name)\n","\n","  # Sort the data by beta values\n","  sorted_betas = sorted(natural_accuracies.keys())\n","  sorted_natural_accuracies = [natural_accuracies[beta] for beta in sorted_betas]\n","  sorted_robustness_accuracies = [robustness_accuracies[beta] for beta in sorted_betas]\n","\n","  # Plotting the data\n","  plt.figure(figsize=(10, 5))\n","\n","  # Natural accuracy vs beta\n","  plt.plot(sorted_betas, sorted_natural_accuracies, label='Natural Accuracy', marker='o')\n","\n","  # Robustness accuracy vs beta\n","  plt.plot(sorted_betas, sorted_robustness_accuracies, label='Robustness Accuracy', marker='x')\n","\n","  # Adding title and labels\n","  plt.title('Natural and Robustness Accuracy vs Beta')\n","  plt.xlabel('Beta')\n","  plt.ylabel('Accuracy')\n","\n","  # Adding legend\n","  plt.legend()\n","  plt.savefig(os.path.join('plots', 'ACCURACY_SEPARATE.png'))\n","  plt.close()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def make_result_plot_separate():\n","\n","  # Define the directory where the JSON files are located\n","  directory = 'results/'\n","\n","  # Initialize dictionaries to hold the beta values and corresponding accuracies\n","  natural_accuracies = {}\n","  robustness_accuracies = {}\n","\n","  # Define the configuration pattern we're interested in\n","  config_pattern = 'CIFARC10:Alexnet:TRADES_LOSS:BETA='\n","\n","  # Function to extract beta and accuracies from the json file\n","  def extract_data(file_name):\n","      with open(os.path.join(directory, file_name), 'r') as file:\n","          data = json.load(file)\n","          for config_id, accuracy in data.items():\n","              if config_id.startswith(config_pattern):\n","                  # Extract beta value from the configuration ID\n","                  beta = float(config_id.split('=')[-1])\n","                  if 'final_loss' not in file_name:\n","                      if 'natural_accuracy' in file_name:\n","                          natural_accuracies[beta] = accuracy\n","                      elif 'robustness_accuracy' in file_name:\n","                          robustness_accuracies[beta] = accuracy\n","\n","  # Read data from each JSON file\n","  for file_name in os.listdir(directory):\n","      if file_name.endswith('.json'):\n","          extract_data(file_name)\n","\n","  # Sort the data by beta values\n","  sorted_betas = sorted(natural_accuracies.keys())\n","  sorted_natural_accuracies = [natural_accuracies[beta] for beta in sorted_betas]\n","  sorted_robustness_accuracies = [robustness_accuracies[beta] for beta in sorted_betas]\n","\n","  # Create a figure with two subplots\n","  fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(10, 10))\n","\n","  # Plot natural accuracy vs beta\n","  ax1.plot(sorted_betas, sorted_natural_accuracies, label='Natural Accuracy', marker='o')\n","  ax1.set_title('Natural Accuracy vs Beta')\n","  ax1.set_xlabel('Beta')\n","  ax1.set_ylabel('Natural Accuracy')\n","  ax1.legend()\n","\n","  # Plot robustness accuracy vs beta\n","  ax2.plot(sorted_betas, sorted_robustness_accuracies, label='Robustness Accuracy', marker='x')\n","  ax2.set_title('Robustness Accuracy vs Beta')\n","  ax2.set_xlabel('Beta')\n","  ax2.set_ylabel('Robustness Accuracy')\n","  ax2.legend()\n","\n","  # Adjust layout to prevent overlap\n","  plt.tight_layout()\n","  plt.savefig(os.path.join('plots', 'ACCURACY_COMBINED.png'))\n","  plt.close()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["make_result_plot_separate()\n","make_result_plot_combined()"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
