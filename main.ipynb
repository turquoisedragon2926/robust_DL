{"cells":[{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":349,"status":"ok","timestamp":1699074477977,"user":{"displayName":"Turquoise Dragon","userId":"08320414478638444844"},"user_tz":240},"id":"oMU-5NWxiY-7","outputId":"8c58c47b-eaf8-4507-983b-d5c6d0044ae2"},"outputs":[{"ename":"ModuleNotFoundError","evalue":"No module named 'google'","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/var/folders/n5/nz476b1n6m7g84yz5msr7gn80000gn/T/ipykernel_35585/56396362.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cd'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'/content/drive/MyDrive/robust_DL'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google'"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","%cd /content/drive/MyDrive/robust_DL"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from __future__ import print_function\n","import os\n","import argparse\n","import torch.nn as nn\n","import torchvision\n","import numpy as np\n","import torch.nn.functional as F\n","from losses.trades import trades_loss\n","import copy\n","import torch\n","import torch.optim as optim\n","from torch.autograd import Variable\n","from torchvision import datasets, transforms\n","from models.wideresnet import *\n","from models.resnet import *\n","from models.small_cnn import *\n","from torch.utils.data import Dataset, DataLoader\n","from models.AlexNet import AlexNet\n","from torch.utils.data.sampler import SubsetRandomSampler"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["class Data:\n","  def __init__(self, train_loader, valid_loader, test_loader, attack_loader):\n","    self.train_loader = train_loader\n","    self.valid_loader = valid_loader\n","    self.test_loader = test_loader\n","    self.attack_loader = attack_loader\n","\n","class Model:\n","  model = None\n","  def __init__(self, id):\n","    self.id = id\n","\n","class Loss:\n","  def __init__(self, loss_fn, id=None):\n","    self.loss_fn = loss_fn\n","    self.id = id\n","\n","class Configuration:\n","  def __init__(self, data, model, loss, attack, model_pt=None, id=None):\n","    self.data = data\n","    self.model = model\n","    self.loss = loss\n","    self.attack = attack\n","    self.model_pt = model_pt # Should move this to model\n","\n","    self.id = id\n","\n","  def getConfig(self):\n","    return self.data, self.model, self.loss, self.attack\n","\n","  def getId(self):\n","    return self.id\n","\n","class CIFAR10CDataset(Dataset):\n","    def __init__(self, data, labels, transform=None):\n","        self.data = data\n","        self.labels = labels\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        image = self.data[idx]\n","        label = self.labels[idx]\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, label\n","\n","def general_trades_loss_fn(beta=6.0, epsilon=0.3, step_size=0.007, num_steps=10):\n","  def trades_loss_fn(model, data, target, optimizer):\n","    return trades_loss(model=model, x_natural=data, y=target, optimizer=optimizer, step_size=step_size,\n","                      epsilon=epsilon, perturb_steps=num_steps, beta=beta, distance='l_inf')\n","  return trades_loss_fn\n","\n","def identity_attack(model, X, y):\n","  out = model(X)\n","  acc = (out.data.max(1)[1] == y.data).float().sum()\n","  return acc.item()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n","def accuracy(model, data_loader, device):\n","    print('claculating accuracy')\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for batch_idx, (data, target) in enumerate(data_loader):\n","            data, target = data.to(device), target.to(device)\n","            outputs = model(data)\n","            _, predicted = torch.max(outputs, 1)\n","            total += target.size(0)\n","            correct += (predicted == target).sum().item()\n","\n","    return 100. * correct / total\n","\n","def robust_accuracy(model, attack, data_loader, device):\n","    print('evaluating robust accuracy')\n","    model.eval()\n","    correct = 0\n","    total = 0\n","\n","    for data, target in data_loader:\n","        data, target = data.to(device), target.to(device)\n","\n","        X, y = Variable(data, requires_grad=True), Variable(target)\n","        correct_count = attack(model, X, y)\n","        correct += correct_count\n","        total += target.size(0)\n","    return 100. * correct / total \n","\n","def train(model, data_loader, valid_dataloader, loss, config, epochs, eval_interval, device):\n","  print('starting train')\n","\n","  optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n","  # TODO: We can move the optimizer to a field of Loss object\n","\n","  model.to(device)\n","  if config.model_pt is not None:\n","    model.load_state_dict(torch.load(config.model_pt))\n","\n","  best_eval_acc = 0.0\n","  patience = 5  # number of VAL Acc values observed after best value to stop training\n","\n","  for epoch in range(epochs):\n","    model.train()\n","    total_loss = 0.0\n","    for batch_idx, (data, target) in enumerate(data_loader):\n","        data, target = data.to(device), target.to(device)\n","        optimizer.zero_grad()\n","        l = loss.loss_fn(model, data, target, optimizer)\n","        l.backward()\n","        optimizer.step()\n","        total_loss += l.item()\n","\n","        print(loss.id + \" @ Batch idx \" + str(batch_idx) + \" / \" + str(len(data_loader) - 1))\n","    if epoch ==1 or epoch % eval_interval == 0 or epoch == epochs:\n","      eval_acc= accuracy(model, valid_dataloader, device)\n","\n","      if (eval_acc > best_eval_acc):  # best so far so save checkpoint to restore later\n","        best_eval_acc = eval_acc\n","        patience_count = 0\n","        torch.save(model.state_dict(), os.path.join(\"weights\", loss.id + \".pt\"))\n","        torch.save(optimizer.state_dict(), os.path.join(\"optimizers\", loss.id +  \".tar\"))\n","      else:\n","          patience_count += 1\n","          if patience_count >= patience:\n","              print(f\"Early Stopping!, epoch {epoch}\")\n","              break\n","\n","    \n","\n","  return total_loss\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["def run_experiment(num_epoch=2, valid_size=0.2, eval_interval=1):\n","  transform_train = transforms.Compose([\n","    transforms.RandomCrop(32, padding=4),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),])\n","  transform_test = transforms.Compose([\n","    transforms.ToTensor(),])\n","  use_cuda = torch.cuda.is_available()\n","  kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n","  transform_attack = transforms.Compose([transforms.ToTensor(),])\n","\n","  trainset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform_train)\n","  validset = torchvision.datasets.CIFAR10(root='data', train=True, download=True, transform=transform_train)\n","  testset = torchvision.datasets.CIFAR10(root='data', train=False, download=True, transform=transform_test)\n","  num_train = len(trainset)\n","  indices = list(range(num_train))\n","  split = int(np.floor(valid_size * num_train))\n","  train_idx, valid_idx = indices[split:], indices[:split]\n","  train_sampler = SubsetRandomSampler(train_idx)\n","  valid_sampler = SubsetRandomSampler(valid_idx)\n","\n","\n","  cifar10_train_loader = torch.utils.data.DataLoader(trainset, batch_size=128, sampler=train_sampler, **kwargs)\n","  cifar10_valid_loader = torch.utils.data.DataLoader(trainset , batch_size=128, sampler=valid_sampler, **kwargs)\n","  cifar10_test_loader = torch.utils.data.DataLoader(testset, batch_size=128, shuffle=False, **kwargs)\n","\n","\n","  transform_cifar10c = transforms.Compose([\n","    transforms.ToPILImage(),\n","    transforms.ToTensor(),\n","    transforms.Normalize((0.5,), (0.5,))])\n","  images = np.load('data/CIFAR-10-C/spatter.npy') # Set this to whatever we want\n","  labels = np.load('data/CIFAR-10-C/labels.npy')\n","  cifar10c_dataset = CIFAR10CDataset(data=images[:200],labels=labels[:200],transform=transform_cifar10c)\n","  cifar10c_attack_loader = DataLoader(cifar10c_dataset, batch_size=200, shuffle=False)\n","\n","  cifar10_c_data = Data(cifar10_train_loader, cifar10_valid_loader,cifar10_test_loader, cifar10c_attack_loader)\n","  device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","\n","  for beta in [0.6]:\n","    id = f'CIFARC10:Alexnet:TRADES_LOSS:BETA={beta}'\n","    # model_pt = os.path.join(\"weights\", f'CIFARC10:RESNET18:TRADES_LOSS:BETA={beta}_ep=0.pt')\n","    model_pt=None\n","    # resnet18 = ResNet18().to(device)\n","    alexnet = AlexNet().to(device)\n","    trades_loss_beta = Loss(general_trades_loss_fn(beta=beta), id)\n","    config1 = Configuration(cifar10_c_data, alexnet, trades_loss_beta, identity_attack, model_pt, trades_loss_beta.id)\n","    configurations = []\n","    configurations.append(config1)\n","\n","    training_loss = {}\n","    natural_accuracy = {}\n","    robustness_accuracy = {}\n","\n","    for (c, configuration) in enumerate(configurations):\n","       data, model, loss, attack = configuration.getConfig()\n","       training_loss[configuration.getId()] = train(model, data.train_loader,data.valid_loader,  loss, configuration,num_epoch,eval_interval, device)\n","       print(training_loss[configuration.getId()])\n","       natural_accuracy[configuration.getId()] = accuracy(model, data.test_loader, device)\n","       print(natural_accuracy[configuration.getId()])\n","       robustness_accuracy[configuration.getId()] = robust_accuracy(model, attack, data.attack_loader, device)\n","       print(robustness_accuracy[configuration.getId()] )"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["run_experiment(num_epoch=70, valid_size=0.2, eval_interval=1)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"}},"nbformat":4,"nbformat_minor":0}
